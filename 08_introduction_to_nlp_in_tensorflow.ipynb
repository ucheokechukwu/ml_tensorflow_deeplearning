{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "uHjaRFhQQu9G",
        "VZq56IcVgE4b",
        "y3Z1CA9CjbKo",
        "d1JWGs413cu7"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO7KvSq/K1kJDDbrfB+z1E0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ucheokechukwu/ml_tensorflow_deeplearning/blob/main/08_introduction_to_nlp_in_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# introduction to NLP fundamentals in Tensorflow\n",
        "\n",
        "NLP has the goal of deriving information out of natural langauge (could be sequence text or speech).\n",
        "\n",
        "Another common term for NLP problems is sequence to sequence problmes (seq2seq)."
      ],
      "metadata": {
        "id": "M1jZ-_HjP_Wg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## check for GPU\n",
        "!nvidia-smi -L"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "si1Bx7OxQPYw",
        "outputId": "3d8ee50b-d048-4ecf-b18a-2711ef22a4f0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get helper functions\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
        "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quRJ6tSNQTua",
        "outputId": "41947cb7-1af8-4439-e73a-e81accdc4650"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-13 17:05:30--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "helper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-03-13 17:05:30 (31.8 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get a text dataset\n",
        "Kaggle's introduction to NLP dataset. Text samples of tweets labelled as disaster or not disaster. \n",
        "- binary clssification\n",
        "https://www.kaggle.com/c/nlp-getting-started"
      ],
      "metadata": {
        "id": "uHjaRFhQQu9G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
        "unzip_data(\"nlp_getting_started.zip\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwN-uZopRQ2z",
        "outputId": "e5e1213d-d060-4e5d-8c20-b71076ce5b83"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-13 17:05:38--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.13.128, 172.217.193.128, 173.194.210.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.13.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘nlp_getting_started.zip’\n",
            "\n",
            "\rnlp_getting_started   0%[                    ]       0  --.-KB/s               \rnlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.008s  \n",
            "\n",
            "2023-03-13 17:05:38 (68.9 MB/s) - ‘nlp_getting_started.zip’ saved [607343/607343]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing a text dataset\n",
        "\n",
        "to visualize our text samples, we first have to read them in. we can do so using Pandas for Python "
      ],
      "metadata": {
        "id": "-vnu7H-dRX_8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "train_df.head()"
      ],
      "metadata": {
        "id": "cjrrphuSRxTy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "f5870858-075d-424e-f0e1-76a24f7a78d4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id keyword location                                               text  \\\n",
              "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
              "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
              "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
              "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
              "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
              "\n",
              "   target  \n",
              "0       1  \n",
              "1       1  \n",
              "2       1  \n",
              "3       1  \n",
              "4       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-22131904-8317-4705-b322-b6befa6c2434\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-22131904-8317-4705-b322-b6befa6c2434')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-22131904-8317-4705-b322-b6befa6c2434 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-22131904-8317-4705-b322-b6befa6c2434');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df[\"text\"][20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "tkgIJDJtb3Zu",
        "outputId": "1852dd82-ec12-4e25-f73b-0cc9048dd7ff"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'this is ridiculous....'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df_shuffled = train_df.sample(frac=1, random_state=42)"
      ],
      "metadata": {
        "id": "oLZpqtT_cA9k"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df_shuffled.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "2305hsegcLYg",
        "outputId": "b801c585-92e9-40f7-8d8f-16ef47416da7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id      keyword               location  \\\n",
              "2644  3796  destruction                    NaN   \n",
              "2227  3185       deluge                    NaN   \n",
              "5448  7769       police                     UK   \n",
              "132    191   aftershock                    NaN   \n",
              "6845  9810       trauma  Montgomery County, MD   \n",
              "\n",
              "                                                   text  target  \n",
              "2644  So you have a new weapon that can cause un-ima...       1  \n",
              "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n",
              "5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1  \n",
              "132   Aftershock back to school kick off was great. ...       0  \n",
              "6845  in response to trauma Children of Addicts deve...       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7047bfbc-f9d7-484d-b35c-75cfb52d8f51\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2644</th>\n",
              "      <td>3796</td>\n",
              "      <td>destruction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2227</th>\n",
              "      <td>3185</td>\n",
              "      <td>deluge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>7769</td>\n",
              "      <td>police</td>\n",
              "      <td>UK</td>\n",
              "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>191</td>\n",
              "      <td>aftershock</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6845</th>\n",
              "      <td>9810</td>\n",
              "      <td>trauma</td>\n",
              "      <td>Montgomery County, MD</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7047bfbc-f9d7-484d-b35c-75cfb52d8f51')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7047bfbc-f9d7-484d-b35c-75cfb52d8f51 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7047bfbc-f9d7-484d-b35c-75cfb52d8f51');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# what does the text dataframe look like?\n",
        "test_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "xP_7UQEscOhC",
        "outputId": "c30f7782-02a1-4423-9514-dae84eb76239"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id keyword location                                               text\n",
              "0   0     NaN      NaN                 Just happened a terrible car crash\n",
              "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d3fe6fb0-6e0c-4c06-a1b9-513ba9a7d469\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d3fe6fb0-6e0c-4c06-a1b9-513ba9a7d469')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d3fe6fb0-6e0c-4c06-a1b9-513ba9a7d469 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d3fe6fb0-6e0c-4c06-a1b9-513ba9a7d469');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# how many examples of each class are there?\n",
        "train_df.target.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lZ_Ot7KcWlV",
        "outputId": "b0ce4962-97be-4c9f-b2c8-ea3b31d2b6a2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# how many total samples\n",
        "len(train_df), len(test_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqVz1XaAcexV",
        "outputId": "3eaed594-81cf-430d-b33d-cc9507940e6b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7613, 3263)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's visualize some random training examples\n",
        "import random\n",
        "random_index = random.randint(0,len(train_df)-5)\n",
        "for row in train_df_shuffled[[\"text\", \"target\"]][random_index:random_index+5].itertuples():\n",
        "  _, text, target = row\n",
        "  print(f\"Target: {target}\", \"(real disaster)\" if target > 0 else \"(not real disaster)\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"---\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6jvrqt_dWH3",
        "outputId": "f41afc86-db6f-4d5b-9fef-f39ec88686e5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "@CIA hey you guy's i stopped a massacre so you   send the cops to my house to make this town permanently hate me wtf?\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "I think this is my plan for retirement. Check out the weapons of mass instruction! #bookmobile #libraries #reading http://t.co/L2NMywrmq2\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "I feel like death\n",
            "\n",
            "---\n",
            "\n",
            "Target: 1 (real disaster)\n",
            "Text:\n",
            "Tunisia beach massacre linked to March terror attack on museum http://t.co/kuRqLxFiHL\n",
            "\n",
            "---\n",
            "\n",
            "Target: 1 (real disaster)\n",
            "Text:\n",
            "#flood #disaster Bengal floods: CM Mamata Banerjee blames DVC BJP claims state failed to use ... - Economic T... http://t.co/BOZlwr716Z\n",
            "\n",
            "---\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split data into training and validation sets"
      ],
      "metadata": {
        "id": "ky-wrr8pfajo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n",
        "                                                                             train_df_shuffled[\"target\"].to_numpy(),\n",
        "                                                                             test_size=0.1,\n",
        "                                                                             random_state=42)\n",
        "len(train_sentences), len(val_sentences), len(train_labels), len(val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seXcfG7ofZZb",
        "outputId": "465d9ba6-d01b-4a83-98a6-8073222b1c01"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6851, 762, 6851, 762)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the first ten examples\n",
        "train_sentences[:10], train_labels[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-pnrL74fxM6",
        "outputId": "c4f437fb-73d6-45c8-8267-a40b92a196a3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "        'Imagine getting flattened by Kurt Zouma',\n",
              "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
              "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
              "        'destroy the free fandom honestly',\n",
              "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
              "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
              "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
              "       dtype=object), array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Converting text into numbers\n",
        "\n",
        "When dealing with text problem, one of the first things you need to do is numerically encode the text.\n",
        "\n",
        "Methods:\n",
        "\n",
        "1. Tokenization - direct mapping of token (word or character to number) or one-hot encoding.\n",
        "\n",
        "2 - Embedding - creating a matrix of feature vectors for each token. The size of the vector can be defined and this embedding, which is essentially a matrix of weights can be learned."
      ],
      "metadata": {
        "id": "VZq56IcVgE4b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text vectorization (tokenization)"
      ],
      "metadata": {
        "id": "y3Z1CA9CjbKo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "# from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "from tensorflow.keras.layers import TextVectorization"
      ],
      "metadata": {
        "id": "LrBDNUrljkqy"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the default TextVectorization parameters\n",
        "text_vectorizer = TextVectorization(max_tokens=None,\n",
        "                                    standardize=\"lower_and_strip_punctuation\",\n",
        "                                    split=\"whitespace\",\n",
        "                                    ngrams=None,\n",
        "                                    output_mode=\"int\",\n",
        "                                    output_sequence_length=None\n",
        "                                    )"
      ],
      "metadata": {
        "id": "_Cf6UZpGjtmn"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# find the average number of tokens (words) in the training tweets"
      ],
      "metadata": {
        "id": "6c8u_tLXpUBQ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_sentences[0].split())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufcKQ__IpWRg",
        "outputId": "a1cd8d98-0849-4033-cb32-9cc79fec56e3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_hIFrJ7pLk-",
        "outputId": "7fd6d8be-7ac1-4a25-e855-fae2f9ead7d4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set up text vectorization variables\n",
        "max_vocab_length = 10000 #max number of words to have in our vocabulary\n",
        "max_length = 15 # max length our sequences will be (e.g. how many words from a tweet does our model see?)\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
        "                                    output_mode=\"int\",\n",
        "                                    output_sequence_length=max_length)\n",
        "\n",
        "# fit the text vectorizer to the training text\n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "metadata": {
        "id": "zKmGDqFbpofT"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_sentence=\"there is a flood in my street!\"\n",
        "text_vectorizer([sample_sentence])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhu3bCVn00fU",
        "outputId": "b4ea482c-0c69-404b-8ec5-7f17f5afe105"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[ 74,   9,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Note that the shape is (1,15) because we passed it in **1** sequence and **15** is because the max_length is 15."
      ],
      "metadata": {
        "id": "mQJrpkL21Cep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_vectorizer([\"there is a man in my backyard!\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-JeaUrG1QT_",
        "outputId": "50cee860-0d7f-4e94-86e9-d5dba4c4818c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[  74,    9,    3,   89,    4,   13, 6143,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text: \\n{random_sentence}\\n\\n\\nVectorized Version: {text_vectorizer([random_sentence])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1pzKcPg1Wee",
        "outputId": "f8a7c4ed-ec8e-41f2-c416-03e6d83f0123"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text: \n",
            "Beware of your temper and a loose tongue! These two dangerous weapons combined can lead a person to the Hellfire #islam!\n",
            "\n",
            "\n",
            "Vectorized Version: [[4096    6   33 3346    7    3 1819 1748  222  116 1418  258 2515   71\n",
            "  1393]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the unique words in the vocubalary\n",
        "words_in_vocab = text_vectorizer.get_vocabulary() # get all the unique words in our training data\n",
        "top_5_words = words_in_vocab[:10]\n",
        "bottom_5_words = words_in_vocab[-10:]\n",
        "print(f\"Number of words in vocab: {len(words_in_vocab)} \\n\\n5 most common words: \\n{top_5_words}\\n\\n5 least common words: \\n{bottom_5_words}\")\n",
        "# [UNK] is unknown text, that is it's outside of 10000 words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWui7qco1dEF",
        "outputId": "9636be52-9b7d-449d-e3e5-a606126553af"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in vocab: 10000 \n",
            "\n",
            "5 most common words: \n",
            "['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'and', 'i', 'is']\n",
            "\n",
            "5 least common words: \n",
            "['painthey', 'painful', 'paine', 'paging', 'pageshi', 'pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text vectorization (embedding)\n",
        "`tf.keras.layers.Embedding`\n",
        "turns positive integers into dense vectors of fixed size\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding\n",
        "\n",
        "The parameters we care most about for our embedding layer:\n",
        "* `input_dim` - the size of our vocabulary\n",
        "* `output_dim` - the size of the output embedding vector e.g. a value of 100 means each token gets represented by a vector of length 100\n",
        "* `input_length` - the length of sequences passed into the embedding layer (in this case, it's 15)"
      ],
      "metadata": {
        "id": "d1JWGs413cu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "embedding = layers.Embedding(input_dim=max_vocab_length, #set input shape\n",
        "                             output_dim=128, #neural networks work best with numbers divisible by 8\n",
        "                             input_length=max_length # how long is each input\n",
        ")"
      ],
      "metadata": {
        "id": "6uODXpCt_7lW"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test on random sentences from the training set\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text: \\n{random_sentence}\\\n",
        "n\\nEmbedded version:\")\n",
        "# embed the random sentence (turn it into dense vectors of fixed size)\n",
        "sample_embed = embedding(text_vectorizer(random_sentence))\n",
        "sample_embed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIC_T80_A4p1",
        "outputId": "072f3b03-23f4-47d8-c2f2-5b3a51af668a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text: \n",
            "No don't evacuate the students just throw them in the dungeon. That is stupid.n\n",
            "Embedded version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(15, 128), dtype=float32, numpy=\n",
              "array([[-0.0458607 ,  0.01816807, -0.02580811, ..., -0.04666785,\n",
              "         0.0346473 ,  0.02744099],\n",
              "       [ 0.02099374, -0.03005712,  0.00930461, ..., -0.01458265,\n",
              "         0.02010695, -0.02697699],\n",
              "       [ 0.0079918 ,  0.01031456,  0.03410769, ..., -0.00135984,\n",
              "        -0.02071763, -0.01041263],\n",
              "       ...,\n",
              "       [ 0.03802755,  0.00078378,  0.04083348, ..., -0.04772193,\n",
              "        -0.04600535,  0.04822692],\n",
              "       [-0.02552068, -0.03836172, -0.01723952, ...,  0.03295627,\n",
              "        -0.04284518, -0.00408127],\n",
              "       [ 0.03980645, -0.01484523, -0.02595969, ..., -0.0440552 ,\n",
              "        -0.04664922, -0.00611497]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_embed = tf.expand_dims(sample_embed, axis=0)"
      ],
      "metadata": {
        "id": "TW8QleRVBvY-"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check out a single token's embedding\n",
        "sample_embed[0][0], sample_embed[0][0].shape, random_sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGbJECQUCD9a",
        "outputId": "3f28f2c6-f865-4517-c05d-0c823435e8b8"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
              " array([-0.0458607 ,  0.01816807, -0.02580811, -0.03211554,  0.01282436,\n",
              "        -0.01188555, -0.03748599,  0.01447311,  0.00770329, -0.03373734,\n",
              "        -0.04786849, -0.01033177, -0.03739934, -0.0299038 , -0.03773041,\n",
              "         0.00764878, -0.03520491,  0.010307  ,  0.01986578,  0.01575235,\n",
              "        -0.04802128,  0.01620081, -0.02974489, -0.01073744,  0.0077072 ,\n",
              "        -0.033354  , -0.01995434, -0.00134494, -0.03513313,  0.03414101,\n",
              "        -0.02182283, -0.04649058,  0.01975454,  0.01777165, -0.02613107,\n",
              "        -0.00736674, -0.01469647, -0.03670442, -0.00747863, -0.01748114,\n",
              "        -0.04757627,  0.03621948,  0.01499205, -0.04908527,  0.01224456,\n",
              "        -0.02071856, -0.03606253, -0.01804631, -0.0420357 ,  0.01277703,\n",
              "        -0.02817786, -0.03638612, -0.04839441,  0.04215503,  0.01673306,\n",
              "        -0.04128503, -0.00764592,  0.03699971, -0.01620064,  0.02963973,\n",
              "         0.03912009, -0.03050065,  0.01027741,  0.03022255,  0.0348619 ,\n",
              "         0.00735508, -0.009745  ,  0.00602503,  0.01118752, -0.01878482,\n",
              "         0.01286961, -0.01434653,  0.0320032 ,  0.04433549,  0.03623194,\n",
              "        -0.00781989,  0.00378998, -0.00414556,  0.00600868,  0.02976111,\n",
              "         0.00264229,  0.0141126 , -0.02025094,  0.03642977, -0.00138186,\n",
              "        -0.01770877,  0.04842972,  0.03088445,  0.01587633, -0.03606162,\n",
              "         0.00104549, -0.01391875, -0.00466   , -0.03570439, -0.03519697,\n",
              "         0.04453157,  0.03532467,  0.012273  , -0.03584008, -0.01965356,\n",
              "        -0.04509183,  0.01305492,  0.03306429, -0.0257488 ,  0.01426294,\n",
              "         0.01002347,  0.0124822 , -0.0467981 ,  0.02522152, -0.04777184,\n",
              "         0.02064936,  0.00579383, -0.0068089 ,  0.035427  ,  0.02398885,\n",
              "        -0.02658631,  0.04362679,  0.0429664 , -0.01953502,  0.02697103,\n",
              "         0.02094604,  0.02629993,  0.04236716, -0.02376423,  0.02035475,\n",
              "        -0.04666785,  0.0346473 ,  0.02744099], dtype=float32)>,\n",
              " TensorShape([128]),\n",
              " \"No don't evacuate the students just throw them in the dungeon. That is stupid.\")"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelling our text dataset - running a series of experiments\n",
        "\n",
        "It's time to start building a series of modelling experiments, starting with a baseline and moving on from there:\n",
        "\n",
        "* Model 0: Naive Bayes (baseline)\n",
        "* Model 1: feed-forward neural network (dense model)\n",
        "* Model 2: LSTM model (long-short term memory) (RNN)\n",
        "* Model 3: GRU model (RNN)\n",
        "* Model 4: Bidirectional LSTM model (RNN)\n",
        "* Model 5: 1D Convolutional Neural network\n",
        "* Model 6: Tensorflow Hub pretrained feature extracctor (using transfer learning for NLP)\n",
        "* Model 7: same as 6 with 10% of the dataset\n",
        "\n",
        "Method of approach: standard steps with modelling with tensorflow:\n",
        "- prepare data -> build -> compile -> fit -> evaluate -> experiment and improve"
      ],
      "metadata": {
        "id": "JDrDvt0NCtCL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 0 - getting a baseline\n",
        "This will be our baseline model that serves as a benchmark for future experiments to build up. We're going to use `sklearn` Multinomial Naive Bayes using the TF-IDF formula to convert our words to numbers. \n",
        "\n",
        "* 🔑 It's common practice to use non-DL algorithm as a baseline because of their speed and later use DL to see how to improve upon them."
      ],
      "metadata": {
        "id": "WEqrIOv4gRTC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n"
      ],
      "metadata": {
        "id": "pnt8Yo-7g332"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create tokenization and modelling pipeline\n",
        "model_0 = Pipeline([\n",
        "    (\"tfidf\", TfidfVectorizer()), # convert words to numbers using tfidf\n",
        "    (\"clf\", MultinomialNB()) # model the text using this classifier(clf)\n",
        "])\n",
        "\n",
        "# fit the pipeline to the training data\n",
        "model_0.fit(train_sentences, train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "7ItnKXm9hVDn",
        "outputId": "d1424d50-db10-442d-8ffd-b111844f6ba5"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate our baseline model\n",
        "baseline_score = model_0.score(val_sentences, val_labels) \n",
        "#.score is for sklearn what .evaluate is for tensorflow. the default evaluation metric for classification is accuracy"
      ],
      "metadata": {
        "id": "j4vB5DwZhu0g"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Our baseline score achieves an accuracy of {baseline_score*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FV3JqoGXiDFP",
        "outputId": "e6bfe8e0-ee45-4036-8a5e-ee2dc6a28672"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our baseline score achieves an accuracy of 79.27%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make predictions\n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rfz-_9jLiEdq",
        "outputId": "9027a4a1-9b83-4a3a-f7df-af790e38ae07"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating evaluation function\n",
        "def evaluation (model, val_sentences, val_labels):\n",
        "  \"\"\"Function to return the evaluation metrics of a model \n",
        "  given the model and the validation data\n",
        "  \"\"\"\n",
        "  from sklearn.metrics import recall_score, precision_score, classification_report\n",
        "  accuracy = model.score(val_sentences, val_labels)\n",
        "  predicted_labels = model.predict(val_sentences)\n",
        "  precision = precision_score(val_labels, predicted_labels)\n",
        "  recall = recall_score(val_labels, predicted_labels)\n",
        "  report = classification_report(val_labels, predicted_labels)\n",
        "\n",
        "  return accuracy, precision, recall, report"
      ],
      "metadata": {
        "id": "_beCaFfFi9A3"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_evaluation = evaluation(model_0, val_sentences, val_labels)\n",
        "print(f\"Accuracy is: {base_evaluation[0]*100:.2f}%. \\nPrecision Score is:{base_evaluation[1]:.2f}\\\n",
        "\\nRecall Score is: {base_evaluation[2]:.2f} \\\n",
        "\\n\\n\\nClassification Report is {base_evaluation[3]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9emR4zekxaQ",
        "outputId": "448d699c-c4be-4b98-bb25-33d33ccd26a3"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy is: 79.27%. \n",
            "Precision Score is:0.89\n",
            "Recall Score is: 0.63 \n",
            "\n",
            "\n",
            "Classification Report is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.93      0.83       414\n",
            "           1       0.89      0.63      0.73       348\n",
            "\n",
            "    accuracy                           0.79       762\n",
            "   macro avg       0.82      0.78      0.78       762\n",
            "weighted avg       0.81      0.79      0.79       762\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating evaluation function\n",
        "def calculate_results (y_true, y_preds):\n",
        "  \"\"\"Function to return the evaluation metrics of a model \n",
        "  given the model and the validation data\n",
        "  \"\"\"\n",
        "  from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "  model_accuracy = accuracy_score(y_true, y_preds) *100\n",
        "  \n",
        "  model_prediction, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_preds,\n",
        "                                                                                average=\"weighted\")\n",
        "  model_results = {\"accuracy\": model_accuracy,\n",
        "                   \"prediction\": model_prediction,\n",
        "                   \"recall\": model_recall,\n",
        "                   \"f1_score\": model_f1}\n",
        "\n",
        "  return model_results"
      ],
      "metadata": {
        "id": "UU5b7TwVmPVQ"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_results = calculate_results(val_labels, baseline_preds)\n",
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rH3HNDiknkh6",
        "outputId": "9f156f52-ecc5-4dec-b1da-ed023335669a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'prediction': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706,\n",
              " 'f1_score': 0.7862189758049549}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 1: Feedforward neural networks (dense model)\n"
      ],
      "metadata": {
        "id": "OFOtZX-RoEhA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensorboard callback\n",
        "from helper_functions import create_tensorboard_callback\n",
        "SAVE_DIR = 'model_logs'"
      ],
      "metadata": {
        "id": "g9DVnwo9O-dA"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build model with Functional API\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string) # or \"string\" Inputs are 1-dimensional strings\n",
        "x = text_vectorizer(inputs) # numerically encode the input texts\n",
        "x = embedding(x) # create an embedding of the numerized numbers\n",
        "x = layers.GlobalAveragePooling1D()(x) # condense the feature vector for each token to one vector\n",
        "# without the above, I kept getting errors\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\")\n",
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eo9Nfmx7PoGm",
        "outputId": "5f5baa12-a467-417b-960a-f5d8da0313b9"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 128)              0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZhXKtmyG2usz"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile model\n",
        "model_1.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=\"Adam\",\n",
        "                metrics=\"accuracy\")"
      ],
      "metadata": {
        "id": "lw8dEqO4QYXR"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit the model\n",
        "history_1 = model_1.fit(x=train_sentences,\n",
        "                        y=train_labels,\n",
        "                        epochs=5,\n",
        "                        validation_data=(val_sentences, val_labels),\n",
        "                        callbacks=[create_tensorboard_callback(SAVE_DIR,experiment_name=\"Model_1_Dense\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LfSQBVtRICy",
        "outputId": "8fb0b8f1-73ed-4c4d-9231-e3173eec4ce6"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/Model_1_Dense/20230313-170547\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 14s 53ms/step - loss: 0.6110 - accuracy: 0.6891 - val_loss: 0.5360 - val_accuracy: 0.7507\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 7s 32ms/step - loss: 0.4427 - accuracy: 0.8167 - val_loss: 0.4705 - val_accuracy: 0.7808\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 7s 32ms/step - loss: 0.3478 - accuracy: 0.8616 - val_loss: 0.4646 - val_accuracy: 0.7861\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 7s 34ms/step - loss: 0.2849 - accuracy: 0.8894 - val_loss: 0.4614 - val_accuracy: 0.7861\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 6s 29ms/step - loss: 0.2382 - accuracy: 0.9137 - val_loss: 0.4899 - val_accuracy: 0.7887\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_1 = model_1.evaluate(val_sentences, val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsYLz93Hj30Z",
        "outputId": "34b10674-99a5-42c9-ec76-4a09d962ff6b"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 5ms/step - loss: 0.4899 - accuracy: 0.7887\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYrRfvpRj-B4",
        "outputId": "5cf11f57-eea8-4ebf-b3fc-48db2f3d27bc"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'prediction': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706,\n",
              " 'f1_score': 0.7862189758049549}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_preds_probs = model_1.predict(val_sentences)\n",
        "model_1_preds_probs[:10], model_1_preds_probs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCiY-LDXkG0M",
        "outputId": "55698086-0b41-483e-d94a-01af2cbe1b7c"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0.32291383],\n",
              "        [0.75132406],\n",
              "        [0.99749315],\n",
              "        [0.08116034],\n",
              "        [0.09392211],\n",
              "        [0.92382145],\n",
              "        [0.90879637],\n",
              "        [0.9914016 ],\n",
              "        [0.95665306],\n",
              "        [0.21461754]], dtype=float32), (762, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert model prediction probabilities to label format and squeeze out the extra dimension\n",
        "model_1_preds=tf.round(tf.squeeze(model_1_preds_probs))\n",
        "model_1_preds[:10]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBxuEWNf3Jd1",
        "outputId": "b83d7c85-66a3-42a7-c265-061c40581d0e"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate model_1 results\n",
        "model_1_results = calculate_results(y_true=val_labels,\n",
        "                                    y_preds=model_1_preds)\n",
        "model_1_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiufTJWg3PbQ",
        "outputId": "ebffa00f-5195-4c13-c794-4f91c072bee6"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.87139107611549,\n",
              " 'prediction': 0.7964015586347394,\n",
              " 'recall': 0.7887139107611548,\n",
              " 'f1_score': 0.7848945056280915}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWJ3Iwtj3v2S",
        "outputId": "c5fdd8b0-a486-47ca-f06e-b15642b7682e"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'prediction': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706,\n",
              " 'f1_score': 0.7862189758049549}"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare the results\n",
        "import numpy as np\n",
        "np.array(list(model_1_results.values())) > np.array(list(baseline_results.values()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGSvD8gM307p",
        "outputId": "253cb5ec-c737-43a7-e4a4-72ce0fddb8a5"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False, False, False])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* None of the metrics were greater than the baseline!"
      ],
      "metadata": {
        "id": "E_kF2G9L38gD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualiizng learned embedding"
      ],
      "metadata": {
        "id": "I8GtHgGJ4_eH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get the vocabulary from the text vectorization layer\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "len(words_in_vocab), words_in_vocab[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSzpXV_h5Dmg",
        "outputId": "a7d79216-e7dc-443b-dc41-30638e63226d"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, ['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'and', 'i', 'is'])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHYqQfNI5OjK",
        "outputId": "f9824643-bed6-44f4-c19c-77e8bef8a608"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 128)              0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the weight matrix of the embedding layer\n",
        "# these are teh numerical represenations of each token in our training data which has been trained for 5 epochs\n",
        "\n",
        "embed_weights = model_1.get_layer(\"embedding\").get_weights()\n",
        "embed_weights = tf.squeeze(embed_weights)\n",
        "embed_weights, embed_weights.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_evwWIy6bM8",
        "outputId": "2f7aa822-1443-47ac-f132-b0f23ac95f44"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(10000, 128), dtype=float32, numpy=\n",
              " array([[ 6.03997409e-02,  1.95189205e-03, -4.35978733e-02, ...,\n",
              "         -6.45836964e-02, -6.67870790e-02, -2.47183759e-02],\n",
              "        [ 3.43110748e-02, -1.51894167e-02,  3.54718305e-02, ...,\n",
              "         -1.60110183e-02, -2.66722124e-02,  3.30437683e-02],\n",
              "        [ 3.59281041e-02,  3.48134302e-02, -2.15147156e-05, ...,\n",
              "          5.84828202e-03, -6.71400689e-03, -5.46348169e-02],\n",
              "        ...,\n",
              "        [ 2.69657113e-02,  3.60074677e-02,  9.95416567e-03, ...,\n",
              "          3.83692645e-02,  3.19452174e-02,  1.57534964e-02],\n",
              "        [ 1.43589433e-02,  1.73303168e-02,  2.45586270e-03, ...,\n",
              "         -5.61228357e-02, -3.17440778e-02, -3.27865444e-02],\n",
              "        [ 1.00543626e-01,  8.86800811e-02, -9.33860689e-02, ...,\n",
              "         -6.12838119e-02, -1.00721218e-01, -1.13969699e-01]], dtype=float32)>,\n",
              " TensorShape([10000, 128]))"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Every token is represented by a 128-length vector\n",
        "* Now we've gotten the embedding matrix our model has learned to represent our tokens, let's visualize it.\n",
        "* Tensorflow has a tool: https://projector.tensorflow.org/\n",
        "* and a guide on word embeddings - https://www.tensorflow.org/text/guide/word_embeddings"
      ],
      "metadata": {
        "id": "Ws5DiQHW7Zv3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create embedding files (got from tensorflow word embeddings documentation)\n",
        "import io \n",
        "out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n",
        "out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n",
        "\n",
        "for index, word in enumerate(words_in_vocab):\n",
        "  if index == 0:\n",
        "    continue  # skip 0, it's padding.\n",
        "  vec = embed_weights[index]\n",
        "  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
        "  out_m.write(word + \"\\n\")\n",
        "out_v.close()\n",
        "out_m.close()"
      ],
      "metadata": {
        "id": "Y0GSMBNr8ePj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "outputId": "d0c29ab6-abd9-4dc9-9e3a-d1203d917735"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-a9671436bb73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mcontinue\u001b[0m  \u001b[0;31m# skip 0, it's padding.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membed_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mout_v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m   \u001b[0mout_m\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mout_v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-51-a9671436bb73>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mcontinue\u001b[0m  \u001b[0;31m# skip 0, it's padding.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membed_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mout_v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m   \u001b[0mout_m\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mout_v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   7325\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_limit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7326\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7327\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7328\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7329\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1177\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m   1051\u001b[0m       \u001b[0mnew_axis_mask\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m<<\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1053\u001b[0;31m       \u001b[0m_check_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1054\u001b[0m       \u001b[0mbegin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m       \u001b[0mend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_check_index\u001b[0;34m(idx)\u001b[0m\n\u001b[1;32m    893\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_check_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m   \u001b[0;34m\"\"\"Check if a given value is a valid index into a tensor.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnumbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIntegral\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDimension\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/abc.py\u001b[0m in \u001b[0;36m__instancecheck__\u001b[0;34m(cls, instance)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__instancecheck__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;34m\"\"\"Override for isinstance(instance, cls).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_abc_instancecheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__subclasscheck__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubclass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/abc.py\u001b[0m in \u001b[0;36m__subclasscheck__\u001b[0;34m(cls, subclass)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_abc_instancecheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0;32mdef\u001b[0m \u001b[0m__subclasscheck__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubclass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m             \u001b[0;34m\"\"\"Override for issubclass(subclass, cls).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_abc_subclasscheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubclass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download files from Colab to upload to project\n",
        "try:\n",
        "  from google.colab import files\n",
        "  files.download('vectors.tsv')\n",
        "  files.download('metadata.tsv')\n",
        "except Exception:\n",
        "  pass"
      ],
      "metadata": {
        "id": "MWV_E8oiEB01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Recurrent Neural Networks (RNNs)\n",
        "\n",
        "RNNs are useful for sequence data.\n",
        "\n",
        "the premise of recurrent neural networks is to use the representation of a previous input to aid the representation of a later input.\n",
        "\n",
        "\n",
        "📖 Resources: Overviews of RNNs are the following - \n",
        "* MIT's sequence modelling lecture\n",
        "* Chris Olah's intro to LSTM - https://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
        "* https://karpathy.github.io/2015/05/21/rnn-effectiveness/"
      ],
      "metadata": {
        "id": "3-0c_heoNjI0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 2: LSTM\n",
        "LSTM - long short term memory\n",
        "\n",
        "our structure of an RNN typically looks like this:\n",
        "\n",
        "``` \n",
        "input(text) -> tokenize -> embedding -> layers (RNN/dense) -> output (label probability)\n",
        "```"
      ],
      "metadata": {
        "id": "Fe86BGU6PIKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create an LSTM model\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "# x = layers.LSTM(units=64, return_sequences=True)(x)\n",
        "# when stacking RNN cells together, need to return Sequences\n",
        "x = layers.LSTM(64)(x)\n",
        "# x = layers.Dense(64, activation=\"relu\")(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_2 = tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")\n",
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8q8QsCgpWnYC",
        "outputId": "9afb126c-9c80-4622-8e04-77bbb58afd9d"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2_LSTM\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 64)                49408     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,329,473\n",
            "Trainable params: 1,329,473\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compile and fit\n",
        "model_2.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=\"Adam\",\n",
        "                metrics=\"accuracy\")\n",
        "history_2 = model_2.fit(train_sentences, train_labels,\n",
        "                        validation_data=(val_sentences, val_labels),\n",
        "                        epochs=5,\n",
        "                        callbacks=create_tensorboard_callback(SAVE_DIR, experiment_name=\"model_2_LSTM\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pF89Zk5nY1qJ",
        "outputId": "078bce14-0405-4a39-d61f-9911919b55a3"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_2_LSTM/20230313-171051\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 12s 41ms/step - loss: 0.2267 - accuracy: 0.9127 - val_loss: 0.6846 - val_accuracy: 0.7743\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 7s 31ms/step - loss: 0.1538 - accuracy: 0.9426 - val_loss: 0.5952 - val_accuracy: 0.7795\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.1254 - accuracy: 0.9526 - val_loss: 0.6581 - val_accuracy: 0.7769\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.1033 - accuracy: 0.9603 - val_loss: 0.8028 - val_accuracy: 0.7835\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 7s 34ms/step - loss: 0.0850 - accuracy: 0.9670 - val_loss: 0.7382 - val_accuracy: 0.7703\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make predictions with LSTM model\n",
        "model_2_pred_probs = model_2.predict(val_sentences)\n",
        "model_2_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlYBDrkIaHaZ",
        "outputId": "d55228f0-3104-450b-a9a3-442824e32cb4"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 7ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.01208567],\n",
              "       [0.759593  ],\n",
              "       [0.9995072 ],\n",
              "       [0.13979708],\n",
              "       [0.00111495],\n",
              "       [0.9867425 ],\n",
              "       [0.58826125],\n",
              "       [0.99946874],\n",
              "       [0.9991367 ],\n",
              "       [0.55757886]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2_preds = tf.round(tf.squeeze(model_2_pred_probs))"
      ],
      "metadata": {
        "id": "VouqX8C6ZHlC"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2_results = calculate_results(y_true = val_labels, y_preds= model_2_preds)\n",
        "model_2_results, baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DECly0VkaXnx",
        "outputId": "187c5991-cc4e-42ee-d7f1-d61529a290ee"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'accuracy': 77.03412073490814,\n",
              "  'prediction': 0.7715893693867238,\n",
              "  'recall': 0.7703412073490814,\n",
              "  'f1_score': 0.7684486602580174},\n",
              " {'accuracy': 79.26509186351706,\n",
              "  'prediction': 0.8111390004213173,\n",
              "  'recall': 0.7926509186351706,\n",
              "  'f1_score': 0.7862189758049549})"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(list(model_2_results.values()))>np.array(list(baseline_results.values()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X79xjyIEamoj",
        "outputId": "f8e32907-187b-4c2c-e35b-c8972119cb5c"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False, False, False])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 3: GRU\n",
        "\n",
        "GRU (Gated recurrent unit) cell has similar features to LSTM but less parameters"
      ],
      "metadata": {
        "id": "_ZouDvIDcAiQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.GRU(64)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_3 = tf.keras.Model(inputs, outputs, name=\"model_3_GRU\")\n",
        "model_3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQ9du6P7cCiM",
        "outputId": "802c3e88-0f13-4d24-ccf2-ed2ac96c9c6d"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3_GRU\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 64)                37248     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,317,313\n",
            "Trainable params: 1,317,313\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=\"Adam\",\n",
        "                metrics=\"accuracy\")\n",
        "history_3 = model_3.fit(train_sentences, train_labels,\n",
        "            validation_data=(val_sentences, val_labels),\n",
        "            epochs=5,\n",
        "            callbacks=[create_tensorboard_callback(SAVE_DIR, experiment_name=\"model_3_GRU\")]\n",
        "    \n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGWf2c5pcz72",
        "outputId": "23d98d5d-90ae-40e4-f92d-9c8fea4459d0"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_3_GRU/20230313-171134\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 12s 38ms/step - loss: 0.1603 - accuracy: 0.9333 - val_loss: 0.7627 - val_accuracy: 0.7703\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 9s 41ms/step - loss: 0.0834 - accuracy: 0.9683 - val_loss: 0.7875 - val_accuracy: 0.7782\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 10s 45ms/step - loss: 0.0727 - accuracy: 0.9726 - val_loss: 0.8197 - val_accuracy: 0.7769\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 7s 33ms/step - loss: 0.0665 - accuracy: 0.9758 - val_loss: 1.1730 - val_accuracy: 0.7756\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0558 - accuracy: 0.9753 - val_loss: 0.9131 - val_accuracy: 0.7769\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the data\n",
        "model_3_preds_probs = model_3.predict(val_sentences)\n",
        "model_3_preds = tf.round(tf.squeeze(model_3_preds_probs))\n",
        "model_3_results = calculate_results(y_true=val_labels, y_preds=model_3_preds)\n",
        "model_3_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "id9f0usJeSJ7",
        "outputId": "337fd9a2-cde4-4b03-bc52-61f1f2937884"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 9ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.69028871391076,\n",
              " 'prediction': 0.7836526472838238,\n",
              " 'recall': 0.7769028871391076,\n",
              " 'f1_score': 0.7729557843731072}"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N84SFAKSfYqv"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(list(results_3))>np.array(list(baseline_results))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "bXBh9Q0JfVg_",
        "outputId": "f3c69427-0f00-4126-e266-fe85c0db969d"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-962b06f9ee53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbaseline_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'results_3' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_predictions_and_results(model, val_sentences=val_sentences, val_labels=val_labels):\n",
        "  model_pred_probs = model.predict(val_sentences)\n",
        "  model_preds = tf.squeeze(tf.round(model_pred_probs))\n",
        "  model_results = calculate_results(val_labels, model_preds)\n",
        "  print(np.array(list(model_results.values()))>np.array(list(baseline_results.values())))\n",
        "  \n",
        "  return model_results"
      ],
      "metadata": {
        "id": "5O2DpQZbfhNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_3_results = calculate_predictions_and_results(model_3)"
      ],
      "metadata": {
        "id": "CvPvDxxFgPE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 4: Bidirectional RNN\n",
        "\n",
        "* Normal RNN go in one direction (left to right, for English for example),\n",
        "* bidirectional RNN go from right to left as well as left to right"
      ],
      "metadata": {
        "id": "Jl4Jq_tdgQXB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "# x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
        "# x = layers.Bidirectional(layers.GRU(64))(x)\n",
        "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_4 = tf.keras.Model(inputs, outputs, name=\"model_4_bidirectional\")\n",
        "model_4.summary()"
      ],
      "metadata": {
        "id": "vur6Z-AtlOV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Note: how the shape of the bidirectional layer is twice its input i.e. 64 becomes 128"
      ],
      "metadata": {
        "id": "TBOrtgNRlxCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_4.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=\"Adam\",\n",
        "                metrics=\"accuracy\")\n",
        "history_4 = model_4.fit(train_sentences, train_labels,\n",
        "                        validation_data=(val_sentences, val_labels),\n",
        "                        epochs=5,\n",
        "                        callbacks=[create_tensorboard_callback(SAVE_DIR, \"model_4_bidirectional\")])"
      ],
      "metadata": {
        "id": "sQ9-_3H2m4HT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_4_results = calculate_predictions_and_results(model_4)\n",
        "model_4_results"
      ],
      "metadata": {
        "id": "KSTUfCmqnJsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 5: Conv1D\n",
        "\n",
        "Convolutional Neural Networks for texts (and other types of sequences)\n",
        "\n",
        "we've used CNNs for iamges but images are usually 2D but text data is 1D.\n",
        "previously we've used `conv2D` for image data, but now we'll use `conv1D`\n",
        "\n",
        "```\n",
        "\n",
        "inputs(text) -> tokenization -> embedding -> layers(conv1D & pooling) -> output layer\n",
        "```"
      ],
      "metadata": {
        "id": "DcJ2YlNlnNXo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test out our embedding layer, conv1D layer and max pooling\n",
        "embedding_test = embedding(text_vectorizer([\"this is a test sentence\"]))\n",
        "conv_1d = layers.Conv1D(filters=64,\n",
        "                        kernel_size=5,\n",
        "                        activation=\"relu\",\n",
        "                        padding=\"valid\")\n",
        "conv_1d_output = conv_1d(embedding_test)\n",
        "max_pool = layers.GlobalMaxPool1D()\n",
        "max_pool_output = max_pool(conv_1d_output) # get the most important feature\n",
        "\n",
        "embedding_test.shape, conv_1d_output.shape, max_pool_output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhB8a3ANpsDb",
        "outputId": "41a3cd45-f46f-43f4-a28d-ff5135eec8bd"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([1, 15, 128]), TensorShape([1, 11, 64]), TensorShape([1, 64]))"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# building the model\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = conv_1d(x)\n",
        "x = max_pool(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_5 = tf.keras.Model(inputs, outputs, name=\"model_5_cnn\")\n",
        "model_5.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4BqF5ZHqy63",
        "outputId": "bd992270-eef4-4e8d-a596-a5d51d21ea71"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5_cnn\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_24 (InputLayer)       [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  multiple                 0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       multiple                  1280000   \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 11, 64)            41024     \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 64)               0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,321,089\n",
            "Trainable params: 1,321,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_5.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=\"Adam\",\n",
        "                metrics=\"accuracy\")\n",
        "history_5 = model_5.fit(train_sentences, train_labels,\n",
        "                        validation_data=(val_sentences, val_labels),\n",
        "                        epochs=5,\n",
        "                        callbacks=[create_tensorboard_callback(SAVE_DIR,\"model_5_cnn\")])"
      ],
      "metadata": {
        "id": "DnaGYwW5snJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_5_results = calculate_predictions_and_results(model_5)\n",
        "model_5_results"
      ],
      "metadata": {
        "id": "WT1O8jKydnA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 6: Using a feature extractor\n",
        "Now we've nuilt some of our own models, let's try and use Transfer Learning for NLP.\n",
        "USE Feature extractor \n",
        "https://www.tensorflow.org/hub/tutorials/semantic_similarity_with_tf_hub_universal_encoder\n",
        "\n",
        "the input is variable length English text and the output is a 512 dimensional vector"
      ],
      "metadata": {
        "id": "Xk8qVopKtsVB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_sentence"
      ],
      "metadata": {
        "id": "SCZUbo9uxCtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
        "embed_samples = embed([sample_sentence,\n",
        "                       \"when you call the universal sentence encoder on a sentence, it turns it into numbers\"])\n",
        "print(embed_samples[0][:50])"
      ],
      "metadata": {
        "id": "tPccSxwEu4Xz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_samples.shape"
      ],
      "metadata": {
        "id": "UGillfcVw4mc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# how to build the feature extractor\n",
        "# create a Keras Layer using the USe pretrained layer\n",
        "encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                              input_shape=[],\n",
        "                              dtype=\"string\",\n",
        "                              trainable=False,\n",
        "                              name=\"USE\")"
      ],
      "metadata": {
        "id": "fIsReYcGxQIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_6 = tf.keras.Sequential([\n",
        "    encoder_layer,\n",
        "    layers.Dense(64, activation=\"relu\"),\n",
        "    layers.Dense(1,activation=\"sigmoid\")\n",
        "    ],\n",
        "    name=\"model_6_USE_feature_extractor\"\n",
        ")\n",
        "model_6.summary()"
      ],
      "metadata": {
        "id": "TzAlfsMsxkuQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_6.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=\"Adam\",\n",
        "                metrics=\"accuracy\")\n",
        "history_6 = model_6.fit(train_sentences, train_labels,\n",
        "                        validation_data=(val_sentences, val_labels),\n",
        "                        epochs=5,\n",
        "                        callbacks=[create_tensorboard_callback(SAVE_DIR, \"model_6_use_feature_extractor\")]\n",
        ")"
      ],
      "metadata": {
        "id": "1b4C0TECx33e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_6_results = calculate_predictions_and_results(model_6)\n",
        "model_6_results"
      ],
      "metadata": {
        "id": "GWF8-UhM0aUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 7: TF Hub Pretrained USE with 10% of the trianing data\n",
        "\n",
        "Replicating model 6 but trained on only 10% of the data. Transfer Learning really helps when you don't have a large dataset."
      ],
      "metadata": {
        "id": "G_c93VR52Ztd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df_shuffled.head()"
      ],
      "metadata": {
        "id": "5q4YXU9E2lCy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_10_percent = train_df_shuffled[[\"text\", \"target\"]].sample(frac=0.1, random_state=42)"
      ],
      "metadata": {
        "id": "5iRAsfZD2p0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_10_percent.head()"
      ],
      "metadata": {
        "id": "n5yULWLt26Di"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences_10_percent=train_10_percent.text.to_list()\n",
        "train_labels_10_percent=train_10_percent.target.to_list()\n",
        "len(train_sentences_10_percent), len(train_labels_10_percent)"
      ],
      "metadata": {
        "id": "so4nj_9Z3IOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the number of our tragers in our subset of data\n",
        "train_10_percent.target.value_counts()"
      ],
      "metadata": {
        "id": "9uJzidPw3QFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df_shuffled.target.value_counts()"
      ],
      "metadata": {
        "id": "tcN5eSDO3pYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cloning models\n",
        "\n",
        "to recreate the same model, you can clone the model\n",
        "`tf.keras.clone_model`\n",
        "it will reset the model with its original weights not the trained models"
      ],
      "metadata": {
        "id": "LNd22hVj3utv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let's build the same model_6\n",
        "model_7 = tf.keras.models.clone_model(model_6)\n",
        "model_7.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=\"Adam\",\n",
        "                metrics=\"accuracy\")\n",
        "model_7.summary()"
      ],
      "metadata": {
        "id": "qqTuNZzv5NJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Can't change the name so we're going to copy and paste this one again!\n",
        "model_7 = tf.keras.Sequential([\n",
        "    encoder_layer,\n",
        "    layers.Dense(64, activation=\"relu\"),\n",
        "    layers.Dense(1,activation=\"sigmoid\")\n",
        "    ],\n",
        "    name=\"model_7_USE_feature_extractor\"\n",
        ")\n",
        "model_7.summary()\n",
        "model_7.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=\"Adam\",\n",
        "                metrics=\"accuracy\")"
      ],
      "metadata": {
        "id": "fBEMiK7L5qKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_7 = model_7.fit(train_sentences_10_percent, train_labels_10_percent,\n",
        "                        validation_data=(val_sentences, val_labels),\n",
        "                        epochs=5,\n",
        "                        callbacks=[create_tensorboard_callback(SAVE_DIR,\"model_7\")])"
      ],
      "metadata": {
        "id": "d45XmUgL6RJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_predictions_and_results(model_7)"
      ],
      "metadata": {
        "id": "5EMLLdzs6hfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_predictions_and_results(model_6)"
      ],
      "metadata": {
        "id": "3frEXTMs6mEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 🤔 Why are the results for 10% of the data better than the results on the full data?\n",
        "\n",
        "Answer: **Data leakage**\n",
        "* Both `train_sentences_10_percent` and `validation_data` are taken from `train_df_shuffled` so there's a good chance that there's an overlap between the two so it's a big no no no in machine learning."
      ],
      "metadata": {
        "id": "tVs7_5Zu69Up"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_10_percent_split = int(0.1* len(train_sentences))\n",
        "train_10_percent_sentences= train_sentences[:train_10_percent_split]\n",
        "train_10_percent_labels=train_labels[:train_10_percent_split]\n",
        "train_10_percent[:10]"
      ],
      "metadata": {
        "id": "22B6tP5q7pF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_10_percent_sentences), len(train_10_percent_labels)"
      ],
      "metadata": {
        "id": "CHdx_Smb8Yv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.Series(train_10_percent_labels).value_counts()"
      ],
      "metadata": {
        "id": "OGapONIe8nqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Can't change the name so we're going to copy and paste this one again!\n",
        "model_8 = tf.keras.Sequential([\n",
        "    encoder_layer,\n",
        "    layers.Dense(64, activation=\"relu\"),\n",
        "    layers.Dense(1,activation=\"sigmoid\")\n",
        "    ],\n",
        "    name=\"model_7_USE_feature_extractor_correct_split\"\n",
        ")\n",
        "model_8.summary()\n",
        "model_8.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=\"Adam\",\n",
        "                metrics=\"accuracy\")"
      ],
      "metadata": {
        "id": "PsCdbZBY8sE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_8 = model_8.fit(train_sentences_10_percent, train_labels_10_percent,\n",
        "                        validation_data=(val_sentences, val_labels),\n",
        "                        epochs=5,\n",
        "                        callbacks=[create_tensorboard_callback(SAVE_DIR,\"model_8\")])"
      ],
      "metadata": {
        "id": "px4eMbjv9Jqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_7_results = calculate_predictions_and_results(model_8)\n",
        "model_7_results"
      ],
      "metadata": {
        "id": "8_jsSkWb9MqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_predictions_and_results(model_6)"
      ],
      "metadata": {
        "id": "vYuAMMfb9SFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparing the performance of each of our models\n"
      ],
      "metadata": {
        "id": "bgzShes29T1j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine model results into DataFrame\n",
        "all_model_results = pd.DataFrame({\"0_baseline\": baseline_results,\n",
        "                                  \"1_simple_dense\": model_1_results,\n",
        "                                  \"2_lstm\": model_2_results,\n",
        "                                  \"3_gru\": model_3_results,\n",
        "                                  \"4_bidirectional\": model_4_results,\n",
        "                                  \"5_conv1d\": model_5_results,\n",
        "                                  \"6_tf_hub_USE_encoder\": model_6_results,\n",
        "                                  \"7_tf_hub_USE_encoder_10_percent\": model_7_results})\n",
        "all_model_results = all_model_results.transpose()\n",
        "all_model_results[\"accuracy\"] = all_model_results[\"accuracy\"]/100\n",
        "all_model_results"
      ],
      "metadata": {
        "id": "D4URJ_rqbtX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot and compare all of the model results\n",
        "all_model_results.plot(kind=\"bar\",\n",
        "                       figsize=(10, 7)).legend(bbox_to_anchor=(1.0, 1.0));"
      ],
      "metadata": {
        "id": "vg8aoCNrfDWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sort model results by f1 score\n",
        "all_model_results.sort_values(\"f1_score\", ascending=False)[\"f1_score\"].plot(kind=\"bar\", figsize=(10,7));\n",
        "# meaning: sort the model results according to f1_score in descending order, then extract the f1 column and plot a bar graph"
      ],
      "metadata": {
        "id": "pePbb8tslr8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! tensorboard dev"
      ],
      "metadata": {
        "id": "vpQOD6xJm4cC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Uploading our model training logs to Tensorboard.dev\n",
        "We can further inspect our performance using Tensorboard.dev"
      ],
      "metadata": {
        "id": "WOqgOxvdnrAS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# upload tensorboard dev records\n",
        "\n",
        "!tensorboard dev upload --logdir /content/model_logs \\\n",
        "--name \"NLP Modelling Experiments ZTM TF Course\" \\\n",
        "--description \"Comparing multiple different types of model architectures on the Kaggle tweets text classification dataset\" \\\n",
        "--one_shot # exit the upload once uploading is finished"
      ],
      "metadata": {
        "id": "YWLvDGYJn4lW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving and loading a trained model\n",
        "There are 2 formats to save a model in Tensorflow:\n",
        "1. HDF5 format\n",
        "2. The `savedmodel` format"
      ],
      "metadata": {
        "id": "d_yrgRibrUpG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model to HDF5 format\n",
        "model_6.save(\"model_6.h5\")"
      ],
      "metadata": {
        "id": "N8x8aNM8yyLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "loaded_model_6 = tf.keras.models.load_model(\"model_6.h5\",\n",
        "                                            custom_objects={\"KerasLayer\":hub.KerasLayer})"
      ],
      "metadata": {
        "id": "3DVCBEaHy4z0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_6_results"
      ],
      "metadata": {
        "id": "fF9C_t3tzLjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate_predictions_and_results(loaded_model_6)"
      ],
      "metadata": {
        "id": "wu9_MK24zcWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save TF Hub encoder to SavedModel format (default)\n",
        "# model_6.save(\"model_6_Savedmodel_format\")"
      ],
      "metadata": {
        "id": "_EvMW8PzzgFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model6_saved_model_format = tf.keras.models.load_model(\"model_6_Savedmodel_format\")"
      ],
      "metadata": {
        "id": "HZ4XvmY2zp0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_predictions_and_results(loaded_model6_saved_model_format)"
      ],
      "metadata": {
        "id": "eEzU1bBVzzRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "bGY0_FCJz2zf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(\"/content/model_6_Savedmodel_format\")"
      ],
      "metadata": {
        "id": "01h7MgWe0JT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finding the most wrong examples\n",
        "\n",
        "* if our best model isn't perfect, what examples is it getting wrong?\n",
        "\n",
        "* and of all these wrong examples, which is getting the most wrong?\n",
        "\n",
        "for example if a sample should have a label of 0, but our model predicts 0.9999 (really close to 1) and vice versa"
      ],
      "metadata": {
        "id": "8vRfFjV30L-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download a pretrained model from Google storage"
      ],
      "metadata": {
        "id": "vz-sSoB80iz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/ztm_tf_course/08_model_6_USE_feature_extractor.zip\n",
        "unzip_data(\"08_model_6_USE_feature_extractor.zip\")"
      ],
      "metadata": {
        "id": "ObSXdv0S0rep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_6_pretrained = tf.keras.models.load_model(\"/content/08_model_6_USE_feature_extractor\")"
      ],
      "metadata": {
        "id": "cSlkF5AH069F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_predictions_and_results(model_6_pretrained)"
      ],
      "metadata": {
        "id": "CHEJoatK1ZQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_6_pretrained_preds_probs = tf.squeeze(model_6_pretrained.predict(val_sentences))\n",
        "\n",
        "model_6_pretrained_preds=tf.round(model_6_pretrained_preds_probs)\n"
      ],
      "metadata": {
        "id": "njeflzfi1b_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataFrame with validation sentences\n",
        "val_df = pd.DataFrame({\"text\": val_sentences,\n",
        "                       \"target\": val_labels,\n",
        "                       \"pred\": model_6_pretrained_preds,\n",
        "                       \"pred_prob\": model_6_pretrained_preds_probs})\n",
        "val_df.head()"
      ],
      "metadata": {
        "id": "iEcDM6qe1phC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(val_df)"
      ],
      "metadata": {
        "id": "n9Eaaiev17Wc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# find the wrong predictions and sort by predition probabilities\n",
        "most_wrong = val_df[val_df.pred != val_df.target].sort_values(\"pred_prob\", ascending=False)\n",
        "most_wrong.head(20) # false positives"
      ],
      "metadata": {
        "id": "NWsh08HD2ukk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "most_wrong.tail(20) # false negatives"
      ],
      "metadata": {
        "id": "JTGwfFDr3Q6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the false positives...\n",
        "for row in most_wrong[:10].itertuples():\n",
        "  _, text, target, pred, pred_prob = row\n",
        "  print(f\"Target: {target}, Pred: {pred}, Prob: {pred_prob}\")\n",
        "  print(f\"Text:\\n{text}\\n--------\\n\")"
      ],
      "metadata": {
        "id": "vEAWTH5Z4qe8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the false negatives...\n",
        "\n",
        "for row in most_wrong[-10:].itertuples():\n",
        "  _, text, target, pred, pred_prob = row\n",
        "  print(f\"Target: {target}, Pred: {pred}, Prob: {pred_prob}\")\n",
        "  print(f\"Text:\\n{text}\\n--------\\n\")"
      ],
      "metadata": {
        "id": "gCp-nBF35wtE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making predictions on the Test Dataset"
      ],
      "metadata": {
        "id": "NtfeOchkdc5V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df"
      ],
      "metadata": {
        "id": "0qwrPpB955Up"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(val_sentences)"
      ],
      "metadata": {
        "id": "MBR7Ygnd6gz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentences = test_df[\"text\"].to_numpy()\n",
        "test_sentences[:10]"
      ],
      "metadata": {
        "id": "vWOEeBMd6mQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred_probs = model_6_pretrained.predict(test_sentences)"
      ],
      "metadata": {
        "id": "tMnGvqz461Ue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred_probs.shape"
      ],
      "metadata": {
        "id": "4QdVk-Zxb-xq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred_probs[:5]"
      ],
      "metadata": {
        "id": "QUCouEItcHmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred_probs=tf.squeeze(test_pred_probs)\n",
        "test_preds = tf.round(test_pred_probs)\n",
        "test_pd = pd.DataFrame({\"text\":test_sentences,\n",
        "                        \"target_predicted\": test_preds,\n",
        "                        \"predict_probabilities\": test_pred_probs})"
      ],
      "metadata": {
        "id": "YXYx3OHIcKYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_pd.head()\n"
      ],
      "metadata": {
        "id": "_gz1D5yTcmgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_pd[test_pd[\"target_predicted\"]==1]"
      ],
      "metadata": {
        "id": "et32SHrrcoxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizing predictions (mrdbourke)"
      ],
      "metadata": {
        "id": "FakFRTrgcv-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing predictions \n",
        "sample_test = random.sample(range(len(test_pd)),5)\n",
        "for sample in sample_test:\n",
        "  print(f\"\\nPred:  {test_pd.loc[sample].target_predicted} \\t Probability: {test_pd.loc[sample].predict_probabilities} \\n\")\n",
        "  print(f\"Text: {test_pd.loc[sample].text} \\n\\n------\\n\")"
      ],
      "metadata": {
        "id": "PsxPnC-9eDs7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_pd.iloc[2].text"
      ],
      "metadata": {
        "id": "izs8arlxeKxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_6_pretrained.predict([\"911\"])"
      ],
      "metadata": {
        "id": "NRgKss-qfdL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The speed/score tradeoff"
      ],
      "metadata": {
        "id": "ErnkGWo1gswY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let's make a function to measure the time of prediction\n",
        "import time\n",
        "def pred_timer(model, samples):\n",
        "  \"\"\"\n",
        "  Times how long a model takes to make predictions on samples\n",
        "  \"\"\"\n",
        "  start_time = time.perf_counter()\n",
        "  model.predict(samples)\n",
        "  end_time = time.perf_counter()\n",
        "  total_time = end_time - start_time\n",
        "  time_per_predictions = total_time/len(samples)\n",
        "  return total_time, time_per_predictions "
      ],
      "metadata": {
        "id": "urtDvx-piBYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate TF Hub Sentence encoder time per pred\n",
        "model_6_total_pred_time, model_6_time_per_pred = pred_timer(model_6_pretrained, samples=val_sentences)"
      ],
      "metadata": {
        "id": "to4HpWKWimYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_6_total_pred_time, model_6_time_per_pred"
      ],
      "metadata": {
        "id": "3tiB66Znixto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate our baseline model times per pred\n",
        "baseline_total_pred_time, baseline_time_per_pred = pred_timer(model_0, samples=val_sentences)\n",
        "baseline_total_pred_time, baseline_time_per_pred"
      ],
      "metadata": {
        "id": "fBLnVGH_i2iH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_6_pretrained_results = calculate_predictions_and_results(model_6_pretrained)"
      ],
      "metadata": {
        "id": "5gaIroZCjOFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "y8LD3oNOl42_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,7))\n",
        "plt.scatter(baseline_time_per_pred, baseline_results[\"f1_score\"], label=\"baseline\")\n",
        "plt.scatter(model_6_time_per_pred, model_6_pretrained_results[\"f1_score\"], label=\"tf_hub_encoder\")\n",
        "plt.legend()\n",
        "plt.title(\"F1-score versus time per prediction\")\n",
        "plt.xlabel(\"Time per prediction\")\n",
        "plt.ylabel(\"F1 Score\")\n",
        "plt.ylim(0.7,0.9)"
      ],
      "metadata": {
        "id": "Rh-wl9J8l8Un"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Question - was the improvement in performance worth the loss in time???"
      ],
      "metadata": {
        "id": "XEe8FmTBmaTe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercises"
      ],
      "metadata": {
        "id": "crliQOkw9e-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Build models 1, 2 and 5 with Sequential API"
      ],
      "metadata": {
        "id": "wrtEkE6z-p8s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_seq = tf.keras.Sequential([\n",
        "    layers.Input(shape=(1,),dtype=\"string\"),\n",
        "    text_vectorizer,\n",
        "    embedding,\n",
        "    layers.GlobalAveragePooling1D(),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "], name=\"model_1_seq\")\n",
        "\n",
        "model_1_seq.compile(loss=\"binary_crossentropy\", optimizer=\"Adam\", metrics=\"accuracy\")\n",
        "model_1_seq.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oetLF0Hu9hX2",
        "outputId": "c4c3cfc7-e08c-442a-ab44-c415e1882f23"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_seq\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " text_vectorization_1 (TextV  multiple                 0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       multiple                  1280000   \n",
            "                                                                 \n",
            " global_average_pooling1d_9   (None, 128)              0         \n",
            " (GlobalAveragePooling1D)                                        \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yIv6XhM-YQ9",
        "outputId": "f9939245-a96a-4670-a871-206894236e01"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 128)              0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2_seq = tf.keras.Sequential([\n",
        "    layers.Input(shape=(1,),dtype=\"string\"),\n",
        "    text_vectorizer,\n",
        "    embedding,\n",
        "    layers.LSTM(64),\n",
        "    layers.Dense(1,activation=\"sigmoid\")\n",
        "], name=\"model_2_seq\")\n",
        "\n",
        "model_2_seq.compile(loss=\"binary_crossentropy\", optimizer=\"Adam\", metrics=\"accuracy\")\n",
        "model_2_seq.summary(), model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EddTLclL-vSx",
        "outputId": "1ddff7a7-a04d-4c99-90a5-a56062e8b653"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2_seq\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " text_vectorization_1 (TextV  multiple                 0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       multiple                  1280000   \n",
            "                                                                 \n",
            " lstm_14 (LSTM)              (None, 64)                49408     \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,329,473\n",
            "Trainable params: 1,329,473\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"model_2_LSTM\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  multiple                 0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       multiple                  1280000   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 64)                49408     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,329,473\n",
            "Trainable params: 1,329,473\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# building the model\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = conv_1d(x)\n",
        "x = max_pool(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_5 = tf.keras.Model(inputs, outputs, name=\"model_5_cnn\")\n",
        "model_5.summary()"
      ],
      "metadata": {
        "id": "Own7pB5h_H_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_5_seq = tf.keras.Sequential([\n",
        "    layers.Input(shape=(1,), dtype=\"string\"),\n",
        "    text_vectorizer,\n",
        "    embedding,\n",
        "    layers.Conv1D(filters=64,\n",
        "                  kernel_size=5,\n",
        "                  activation=\"relu\",\n",
        "                  padding=\"valid\"),\n",
        "    layers.MaxPooling1D(),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model_5_seq.compile(loss=\"binary_crossentropy\", metrics=\"accuracy\", optimizer=\"Adam\")\n",
        "model_5_seq.summary(), model_5.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1TScSAcBrOs",
        "outputId": "d831fa98-fcca-44da-b817-13546deb6fba"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_25\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " text_vectorization_1 (TextV  multiple                 0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       multiple                  1280000   \n",
            "                                                                 \n",
            " conv1d_7 (Conv1D)           (None, 11, 64)            41024     \n",
            "                                                                 \n",
            " max_pooling1d_6 (MaxPooling  (None, 5, 64)            0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 5, 1)              65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,321,089\n",
            "Trainable params: 1,321,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"model_5_cnn\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_24 (InputLayer)       [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  multiple                 0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       multiple                  1280000   \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 11, 64)            41024     \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 64)               0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,321,089\n",
            "Trainable params: 1,321,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eIjlrgCwCKRq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}